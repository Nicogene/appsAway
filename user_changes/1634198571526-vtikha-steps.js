//vtikha
//
//&<h3>Field changed in app: <ins>Supervised Calibration Application</ins></h3><ul><li>with_robot: {content:You have <b>correctly</b> defined the application for your cluster!\nYou just need to <b>download the script</b> on your console and run the following command in a terminal (you can use the copy cmd button for simplicity).\n<code>mkdir -p ~/teamcode/ && mv ~/Downloads/superviseCalib_setup.txt ~/teamcode/superviseCalib_setup.sh && cd ~/teamcode/ && chmod +x superviseCalib_setup.sh && ./superviseCalib_setup.sh</code>\n\n<b>Enjoy</b> the application!</p>,cmd:mkdir -p ~/teamcode/ && mv ~/Downloads/superviseCalib_setup.txt ~/teamcode/superviseCalib_setup.sh && cd ~/teamcode/ && chmod +x superviseCalib_setup.sh && ./superviseCalib_setup.sh,how_to_use:When the GUI is up and running, a list of the different application options will bec<del>a</del><b>o</b>me available:\n\n1. A drop-down list for the **type of camera**: it is possible to choose between <b>`</b>RGB<b>`</b> or <b>`</b>Event Cameras<b>`</b>. Be careful and choose <b>`</b>Event Cameras<b>`</b> only if the robot you want to test the demo on has them. Depending on the chosen type of camera, the content of the **Resolution** drop-down list changes.\n\n2. A drop-down list for the **resolution**: it is possible to choose the resolution of the cameras that will be calibrated. Depending on the chosen resolution, the content of the **Camera Configuration File** drop-down list changes.\n\n3. A checkbox for **Run the cameras manually**: <del>it</del><b>The</b> <del>i</del><b>u</b>s<b>er</b> <del>p</del><b>has the ch</b>o<del>ss</del>i<del>bl</del><b>c</b>e to run <del>manually </del>the camera devices<del>.</del> <del>T</del><b>manually with the c</b>h<del>i</del><b>o</b>s<b>en</b> <b>res</b>o<del>p</del><b>lu</b>tion<b>.</b> <del>impl</del><b>Th</b>i<del>e</del>s <del>n</del>o<b>p</b>t<b>ion</b> <b>di</b>s<del>e</del><b>ab</b>le<del>ct</del><b>s</b> <del>a </del><b>`</b>Camera Configuration File<b>` as the user is doing it manually</b>.<b> </b>\n\n4. A drop-down list for the **Camera Configuration File**: it is possible to select one of the proposed configuration files (`.ini` extension).\n\n5. A checkbox for using a **Custom iCubEyes.ini File**: if ticked, the underlying text input is enabled and <del>there </del>it is possible to specify the path of a custom `iCubEyes.ini`, otherwise the default file `icubEyes.ini`  is used; \n\n6. A checkbox for the **Mono Calibration**: if not ticked, stereo calibration is triggered by default.\n\n   **<del>Ob</del><b>Note</b>s**: The application relies on a configuration file (i.e. `icubEyes.ini` or a custom one) including an initial guess of the intrinsic and extrinsic camera parameters. The calibration procedure provides as result<b>,</b> a refinement of such parameters, which are overwritten in the file. This is done to allow the modules responsible for undistorting the camera images to automatically load the correct file and avoid a manual copy of the calibration result. This implies that running the deployment multiple times, the result of the previous calibration will be <del>l</del>o<del>s</del><b>verwrit</b>t<b>en</b>. For this reason, we recommend saving or renaming this file before running another procedure.\n \n    **How to check the output of the calibration**: if the Camera Configuration File used is a custom one, the output of the calibration will be in the specified file; otherwise, the output of the calibration will be in the path returned by `yarp resource --context cameraCalibration --from icubEyes.ini`\n\nAfter the selection of all the options needed to run the application, the application can be launched pressing the **Start Application** button. As soon as the GUI says 'The application has been deployed!', the demo is ready to be used. Remember that in order to perform the calibration, a **printed chessboard with pattern 8x6** is needed and can be found at [this link](https://github.com/robotology/camera-calibration-supervisor/blob/main/gazebo/models/chessboard/materials/textures/Checkerboard-A4-30mm-8x6-1.jpg). A viewer with a red bounding box will appear: the chessboard need to fit into the bounding box in order to let it becomes green and to proceed in the calibration. Note that with Event-driven Cameras a flashing image is required, such as a chessboard flashing on a tablet. As soon as the calibration will be performed, two viewers will appear showing, as result, the undistorted cameras.}</li></ul>
db.steps.update ({_id: ObjectId("600965c350feaf2f6cb2860b")},{$set: {with_robot: {"content":"You have <b>correctly</b> defined the application for your cluster!\nYou just need to <b>download the script</b> on your console and run the following command in a terminal (you can use the copy cmd button for simplicity).\n<code>mkdir -p ~/teamcode/ && mv ~/Downloads/superviseCalib_setup.txt ~/teamcode/superviseCalib_setup.sh && cd ~/teamcode/ && chmod +x superviseCalib_setup.sh && ./superviseCalib_setup.sh</code>\n\n<b>Enjoy</b> the application!</p>","cmd":"mkdir -p ~/teamcode/ && mv ~/Downloads/superviseCalib_setup.txt ~/teamcode/superviseCalib_setup.sh && cd ~/teamcode/ && chmod +x superviseCalib_setup.sh && ./superviseCalib_setup.sh","how_to_use":"When the GUI is up and running, a list of the different application options will become available:\n\n1. A drop-down list for the **type of camera**: it is possible to choose between `RGB` or `Event Cameras`. Be careful and choose `Event Cameras` only if the robot you want to test the demo on has them. Depending on the chosen type of camera, the content of the **Resolution** drop-down list changes.\n\n2. A drop-down list for the **resolution**: it is possible to choose the resolution of the cameras that will be calibrated. Depending on the chosen resolution, the content of the **Camera Configuration File** drop-down list changes.\n\n3. A checkbox for **Run the cameras manually**: The user has the choice to run the camera devices manually with the chosen resolution. This option disables `Camera Configuration File` as the user is doing it manually. \n\n4. A drop-down list for the **Camera Configuration File**: it is possible to select one of the proposed configuration files (`.ini` extension).\n\n5. A checkbox for using a **Custom iCubEyes.ini File**: if ticked, the underlying text input is enabled and it is possible to specify the path of a custom `iCubEyes.ini`, otherwise the default file `icubEyes.ini`  is used; \n\n6. A checkbox for the **Mono Calibration**: if not ticked, stereo calibration is triggered by default.\n\n   **Notes**: The application relies on a configuration file (i.e. `icubEyes.ini` or a custom one) including an initial guess of the intrinsic and extrinsic camera parameters. The calibration procedure provides as result, a refinement of such parameters, which are overwritten in the file. This is done to allow the modules responsible for undistorting the camera images to automatically load the correct file and avoid a manual copy of the calibration result. This implies that running the deployment multiple times, the result of the previous calibration will be overwritten. For this reason, we recommend saving or renaming this file before running another procedure.\n \n    **How to check the output of the calibration**: if the Camera Configuration File used is a custom one, the output of the calibration will be in the specified file; otherwise, the output of the calibration will be in the path returned by `yarp resource --context cameraCalibration --from icubEyes.ini`\n\nAfter the selection of all the options needed to run the application, the application can be launched pressing the **Start Application** button. As soon as the GUI says 'The application has been deployed!', the demo is ready to be used. Remember that in order to perform the calibration, a **printed chessboard with pattern 8x6** is needed and can be found at [this link](https://github.com/robotology/camera-calibration-supervisor/blob/main/gazebo/models/chessboard/materials/textures/Checkerboard-A4-30mm-8x6-1.jpg). A viewer with a red bounding box will appear: the chessboard need to fit into the bounding box in order to let it becomes green and to proceed in the calibration. Note that with Event-driven Cameras a flashing image is required, such as a chessboard flashing on a tablet. As soon as the calibration will be performed, two viewers will appear showing, as result, the undistorted cameras."}}});
